\chapter{\chResource}
\label{ch:resource}

This chapter discusses the task of monitoring and limiting resource usage.
This task is necessary for the benchmarking process as resource is one of the measurement often selected for comparison.
Section \ref{sec:resource.overview} gives an overview of the task of resource monitoring and its importance.
Three different mechanisms for monitoring resource and its examples are described in Section \ref{sec:resource.mechanism}.
\First~also give a brief description of virtualization as one way to produce more reliable resource measurement in Section \ref{sec:resource.virtualization}.
Finally, we discusses various implementation of resource monitoring tool and each of its mechanism in Section \ref{sec:resource.impl}.

\section{The Task of Resource Monitoring}
\label{sec:resource.overview}

To objectively compare two or more programs, an objective measurement is needed.
Resource consumption like CPU time elapsed, CPU instruction used, or peak memory usage is often considered as the go-to measurement for benchmarking in computational science.
The resources measured might include information regarding processes, threads, computation, memory, input/output, and files of a program \citep{juvePracticalResourceMonitoring2015}.
The task of measuring and limiting these resources can also be described as resource monitoring.

Measurement of these resource consumption is not only used in benchmarking.
Some of its usage includes but not limited to:
its daily usage in user program such as \textit{Task Manager} in Windows or \code{top} in Linux,
judging whether a program passes some threshold marks in education or competition field,
measuring the efficiency of a job scheduling system in High Throughput Computing (HTC) field,
selecting dataset for a competition,
and getting best-enough result from an iterative optimization algorithm after some desired time.
Because of this wide area of usage, there are many attempts to implement these measurement to achieve the best result.

\section{Monitoring Mechanism}
\label{sec:resource.mechanism}

\citet{juvePracticalResourceMonitoring2015} distinguish resource monitoring into three different mechanism.
There are tradeoffs between these mechanisms and so it's often preferred to use a combination of more than one mechanism to achieve better results.

\subsection{Query}

The query approach works by querying resource usage information directly from the operating system.
To monitor the resource usage over time, this means the query is executed at some interval, effectively doing a polling mechanism.
More frequent polling will result in a more timely information but the overhead also increases.
Querying is often the easiest resource monitoring mechanism in term of implementation \citep{juvePracticalResourceMonitoring2015}.

It is the least intrusive mechanism, albeit the information received from this mechanism also immediately expires.
A resource usage surge could happen in between the queries, so this mechanism is not accurate.
In short, the query mechanism provides an easy to implement but inaccurate measurement of the resource monitored.

\code{getrusage()}\footnote{see \href{https://linux.die.net/man/2/getrusage}{\code{man getrusage}}} is a POSIX standard system call.
Unfortunately, this standard only specifies \code{ru\_utime} and \code{ru\_stime}, the user mode time spent and kernel mode time spent, respectively.
In practice, \code{getrusage()} includes more information, for example the \code{ru\_maxrss}, indicating the maximum resident set size.

A Linux specific feature that is often used for querying resource usage is the procfs\footnote{see \href{https://linux.die.net/man/5/proc}{\code{man 5 proc}}} pseudo-file system.
The information provided includes user time, system time, resident set size, number of threads, and many more.
On a side note, since the operating system always account these informations for all running processes, the clock resolution used is not too accurate.
The user time and system time in \code{/proc/[pid]/stat} is measured in system ticks, which turns out to be 10 milliseconds in a typical Linux system.
Recently, Linux control groups (CGroups)\footnote{see \href{http://man7.org/linux/man-pages/man7/cgroups.7.html}{\code{man 7 cgroups}}} is also used for querying similar or more comprehensive information for a group of processes.

A more universal query mechanism is using performance counters.
Most system nowadays---disregarding its operating system---has a hardware clock that has an incredibly accurate clock resolution, some even achieving nanoseconds resolution.
Querying this clock at the start and end of a program could measure what is called the wall clock time.
This measurement is less informative than CPU times measured by user time and system time, but still useful in spite of that.

The library \textsc{psutil}\footnote{\href{https://github.com/giampaolo/psutil}{https://github.com/giampaolo/psutil}} provides an abstraction for various resource queries that works in many operating systems.
This allows a cross-platform resource monitoring tool based on query mechanism to be developed.
As of now however, \first~can't find the relevant resource monitoring tool making use of this abstraction.

It is also need to be noted that this query mechanism cannot work with process tree reliably.
Because of the nature of polling, short living processes can be missed and not accounted to the final result.
This is a strong restriction because most of the computation in HTC or computational science in general often make use of parallelism or concurrency.


\subsection{Notification}

A more reliable mechanism to query a resource usage is to ask the system itself to report the usage on specific events.
This also produces less overhead compared to the query mechanism, although the information queried also immediately expires \citep{juvePracticalResourceMonitoring2015}.

\code{wait4()}\footnote{see \href{https://linux.die.net/man/2/wait4}{\code{man wait4}}} is a system call available in most UNIX that waits for a child process (and blocks the process calling this system call), then returns its \code{getrusage()} information when the process exits.
This one example of the notification mechanism in practice.

\code{inotify}\footnote{see \href{https://linux.die.net/man/7/inotify}{\code{man inotify}}} application programming interface (API) in Linux can also be leveraged.
This API allows one to listen for file system events, such as new file or directory created, existing files edited, a file is accessed, or a file is deleted.
Most operating system also have APIs similar to this, such as \code{fsevents} in OS X. Watchman\footnote{\href{https://facebook.github.io/watchman/}{https://facebook.github.io/watchman/}} is an open source tool by Facebook that abstracts these file system notification APIs.

Another useful notification is \code{forkstat}\footnote{\href{http://manpages.ubuntu.com/manpages/cosmic/en/man8/forkstat.8.html}{http://manpages.ubuntu.com/manpages/cosmic/en/man8/forkstat.8.html}}.
This tool notify system-wide \code{fork()}, \code{exec()}, and \code{exit()} system call activities.
Unfortunately, this tool needs superuser privilege because uses Linux netlink connector, a special socket for communication between kernel and user space.

A more powerful albeit intrusive notification can be achieved by using the UNIX \code{ptrace()}\footnote{see \href{https://linux.die.net/man/2/ptrace}{\code{man ptrace}}} system call.
\code{ptrace()}, often use for debugging, allows a process to intercept and modify system calls.
When a system call occurs, the kernel will check if the process is being traced, and if so, will notify the tracer.
With this system call one can observe, for example, the \code{fork()}, \code{exec()}, and \code{exit()} system call to track process trees.
In Linux, it is also possible to only stop the process when specific, pre-defined system calls occur, these include the three system calls above.

Combining this notifications with the earlier query mechanism can result in a more powerful resource monitoring method.
For example, one can watch for filesystem events on a specific part of the filesystem, such as the \code{/tmp}, \code{/var}, or a specific work directory of the running application. Then when an event occurs, a procfs query is executed to catch the short-living process causing the event is executed.
This effectively allows the procfs query method to work more reliably compared to blindly polling the pseudo-file system.

\subsection{Interposition}

\citet{juvePracticalResourceMonitoring2015} defines this group of mechanism as the ones in which the monitor intercepts actions performed by the process.
This mechanism is highly intrusive because it actively changes the way the program runs.
\code{ptrace()} mentioned earlier also belongs to this group since the kernel stops the system call and forward an event to the monitor (in this case the tracer).
In general this method introduces huge overhead compared to the other mechanism.
In \code{ptrace()} for example, there need to be at least two context switches for every system call intercepted.

A less intrusive method compared to the one \code{ptrace()} used is function interposition.
In this mechanism, the monitor replace some original function by a wrapper that also record parameters and results of the original function \citep{juvePracticalResourceMonitoring2015}.
The environment variable \code{LD\_PRELOAD} in Linux and \code{DYLD\_INSERT\_LIBRARIES} in OS X provides an easy way to load arbitrary library before running a dynamically-linked program.
This way, one can write a wrapper function that will be called instead of the original function.

On the other hand, \code{ptrace()} is less practical because it interrupts each system call made by the program, but it is more robust and can be used in statically-linked programs.
\citet{kimPracticalEffectiveSandboxing2013} has shown that using the recent \code{seccomp/BPF}\footnote{see \href{http://man7.org/linux/man-pages/man2/seccomp.2.html}{\code{man seccomp}}} feature to filter out what system call is going to be intercepted results in an efficient system call interposition technique.

\code{seccomp} is a security feature in Linux (since 2.6.23) to allow only some set of system calls for a program.
Furthermore, Berkeley Packet Filter (\code{BPF}) is also supported since Linux 3.5 as a mean to configure the way \code{seccomp} filters the system call.
With the combination of \code{seccomp} and \code{BPF}, they can configure only some set of the system call to send a \code{ptrace()} event while the rest just continue normally, effectively reducing the overhead of system call interposition.
This feature---usually combined with Linux namespaces---can also be used to provide simple yet secure isolation for the program, as used by \textsc{nsjail}\footnote{see Section \ref{sec:resource.impl.nsjail}} and \textsc{firejail}\footnote{\href{https://github.com/netblue30/firejail/}{https://github.com/netblue30/firejail/}}.

With this interposition mechanism, one can reliably use the query mechanism.
For example, before the \code{exit()} system call actually happen, the \code{procfs} can be queried because the program itself can be stopped before the entry is removed from the pseudo-file system.
While this is the most accurate method compared to the others, this is also highly intrusive so caution must be exercised when using this method.

\section{Virtualization: More Reliable Measurements}
\label{sec:resource.virtualization}

To strengthen the need to produce more reliable resource usage measurement, \citet{beyerReliableBenchmarkingRequirements2019} states isolation of runs as one of the requirements for an accurate and reliable benchmarking.
Specifically, they used Linux containers to provide a lightweight isolation.
Additionally, virtualization tools that are widely used also contributes to reproducibility by providing a programmatic way to pack program dependencies \citep{boettigerIntroductionDockerReproducible2015,kordonBenchKitToolMassive2014}.

\subsection{Virtual Machines}

Virtual machines (VMs) use a technique called hypervisor-based virtualization.
Hypervisor is a software that creates and runs virtual machines \citep{scheepersVirtualizationContainerizationApplication2014}.
There are many of such hypervisor programs that are widely used, examples includes VirtualBox, Xen, Hyper-V, and many more.

Hypervisor manages the resource that will be used by the VMs.
When deployed, each VM run its own operating system with its own kernel.
All the dependencies needed by the program, is also included in the VM itself.
This results in a portable and isolated way to run a program.

Alas, this comprehensive virtualization comes with a cost.
The overhead of bootstrapping a VM is not negligible.
\citet{kordonBenchKitToolMassive2014} reports an average of 40 seconds of booting overhead when this virtualization is used in benchmarking.
\citet{scheepersVirtualizationContainerizationApplication2014} recommends using VMs (compared to containers) when it is important to distribute resources equally and performance should be less dependent from other running tasks.

\subsection{Containers}

A relatively new technique addressing the overhead issue is container-based virtualization.
Linux Containers (LXC)\footnote{\href{https://linuxcontainers.org/}{https://linuxcontainers.org/}} uses this technique to create an isolated environment without hosting multiple kernels like in hypervisor-based virtualization.
The implementation share the Linux kernel with the host machine.
This makes it more lightweight and particularly good for deploying many small isolated instances, as often the case in benchmarking.

Docker\footnote{\href{https://www.docker.com/}{https://www.docker.com/}} is an especially popular tool that utilizes LXC and offer an easy to use interface.
An application built with Docker extends upon existing Docker images with a reproducible \code{Dockerfile} configuration, stating each step needed to create the exact image.
With the key feature of sharing the Linux kernel, an OS image in Docker can achieve minimum size, with a notable example like Alpine Linux even reaching only 2-3 megabytes in size (its virtual machine images is ten times larger in size).

\citet{zhangComparativeStudyContainers2018} report a much less boot up latency---period from starting a VM or container to usable service---in Docker containers compared to VMs.
Booting a VM when there are about 250 other idle VMs takes more than 1000 seconds, while booting 512 Docker contains only takes 987 seconds (an average of 1.89 seconds per container).
This is also true for the amount of memory consumed in idle state.
A VM takes 0.23 GB compared to 0.03 GB of memory of Docker container in their experiment.

A more lightweight containerization or sandboxing technique is using Linux namespaces.
This relatively new feature in the Linux kernel allows isolation of process with practically no overhead.
Both \citet{beyerReliableBenchmarkingRequirements2019} and \citet{marevs2012new} report no overhead from their experiments compared to bare process execution.
This feature allow a few levels of isolation by mix-and-matching various namespaces, namely CGroup, IPC, Network, Mount, PID, User, and UTS\footnote{see \href{http://man7.org/linux/man-pages/man7/namespaces.7.html}{\code{man 7 namespaces}}}.

\section{Implementations}
\label{sec:resource.impl}

We consider some existing implementation and discuss their method of measuring and limiting resource.

\subsection{\textsc{runsolver}}
\label{sec:resource.impl.runsolver}

\textsc{runsolver}\footnote{available at \href{https://www.cril.univ-artois.fr/~roussel/runsolver/}{https://www.cril.univ-artois.fr/~roussel/runsolver/}} \citep{rousselControllingSolverExecution2011} is a resource monitoring and limiting tool for computational task solvers.
The development is driven by competitions such as pseudo-boolean competitions and CSP/MaxCSP competitions.
It is quite popular in the computational science field as it is fairly easy to use and requires no superuser privileges.

The accompanying paper describes the implementation over time.
The first version is just an integration of existing tools like \code{ulimit()}, \code{time}, and \code{ps}.
This version can neither handle multi-process nor sending SIGTERM in the case of out of memory.
The second version uses \code{ptrace()} for interposing system calls, giving it precise control of the processes and memory management system calls.
They report an increase of 60\% to 160\% in CPU time for this second version.
Finally, the third and current version of \textsc{runsolver} polls (at 1 Hz frequency) the list of processes in order to determine the solver's process tree.
The resources is polled from the \code{procfs} and accumulated.

It is not clear whether this tool is still being maintained, but the latest release was on November of 2017.


\subsection{\textsc{runexec}}

\citet{beyerReliableBenchmarkingRequirements2019} provides \textsc{runexec} along with their \textsc{BenchExec} tool as a solution for a reliable benchmarking.
The development was driven by repeated organization of the International Competition on Software Verification (SV-COMP).
It is still being actively developed along with the \textsc{BenchExec} benchmarking framework\footnote{see Section \ref{sec:benchmarking.impl.benchexec}}.

The implementation uses Linux-specific feature CGroups with its various controllers.
The \code{cpuacct} controller is used to measure the CPU time usage.
A separate thread checks the time on predicted time and terminates the process group on timeout.
\code{cpuset} controller is used to attach process groups to specified CPU cores.
\code{freezer} controller is used to freeze and unfreeze the process group when terminating them.
This is to prevent the processes from spawning new processes.
They also used \code{memory} and \code{memsw} controllers to account and limit memory and swap resources.

Additionally, they also provide a non-privileged, optional container-based execution environment, \textsc{containerexecutor}.
It works by combining Linux user namespaces and overlay filesystem features available in Linux kernel 3.8 onwards.
This allows the execution to be isolated from other processes.
The isolation is mainly to address for the frequent interference between program executions caused by using the same directory for storing intermediate files in \code{/tmp} for example.
The PID namespace also allows for a reliable cleanup since other processes will be killed when the \code{init} process is killed inside the namespace.


\subsection{\textsc{kickstart}}

\citet{juvePracticalResourceMonitoring2015} presents \textsc{kickstart}\footnote{available as part of Pegasus: \href{https://github.com/pegasus-isi/pegasus}{https://github.com/pegasus-isi/pegasus}} as one of the tools developed to address monitoring resource usage of HTC tasks.
It is still in active development along with the Pegasus Workflow Management System.

The implementation is UNIX compatible but the feature leveraging \code{ptrace()} is only available in Linux.
The implementation allow several detail of monitoring.
On the lowest detail, it uses \code{wait4()} for the main process.
Then, if specified, it can also use \code{ptrace()} combined with \code{procfs} to catch process-related events to allow more reliable measurement.
Finally, it can also operate full interposition with \code{ptrace()} to capture I/O related information.

Currently, it has no feature for limiting resource usages like CPU time or memory usage.
It is only possible to limit run time (with \code{SIGTERM} and eventually \code{SIGKILL}) by the process wall clock time elapsed.


\subsection{\textsc{timeout}}

\textsc{timeout}\footnote{\href{https://github.com/pshved/timeout}{https://github.com/pshved/timeout}}---not to be confused with a tool with the same name in GNU coreutils with lesser capabilities---is a Perl script for monitoring and limiting time and memory consumption of a process.
It uses \code{ps}\footnote{see \href{https://linux.die.net/man/1/ps}{\code{man ps}}} to scan for related processes and queries from \code{procfs} with a configurable frequency.

It has not been updated since April 2016.
The author also recommends to use CGroups feature instead of using this tool.
They suggests it is a much better method and not limited with some issues occurring with the method used in \textsc{timeout}.

\subsection{\textsc{NsJail}}
\label{sec:resource.impl.nsjail}

\textsc{NsJail}\footnote{\href{https://github.com/google/nsjail}{https://github.com/google/nsjail}}, as described in its project home, is a lightweight process isolation tool for Linux.
It uses several Linux kernel features such as Linux namespaces, CGroups, and \code{seccomp/BPF}.
It is actively being developed by Google security team, although it's not an official Google product.

\textsc{NsJail} is more of a security tool instead of a resource monitoring tool, but it can be used as one to some degree.
The tool allows limiting various resources through CGroup controllers.
Currently there is no report of the actual resource usage, but it can be extended to do so\footnote{see \href{https://github.com/google/nsjail/issues/105}{https://github.com/google/nsjail/issues/105}} by just querying relevant information from the CGroups pseudo-file system.

Utilizing \code{seccomp/BPF} through their separate \textsc{Kafel}\footnote{\href{https://github.com/google/kafel}{https://github.com/google/kafel}} language for configuration, it is possible to specify various system call filtering policies.
For example, one can decide to kill a process when it tries to use \code{execve}, or just log each attempt.


\subsection{\textsc{isolate}}

\textsc{isolate}\footnote{\href{https://github.com/ioi/isolate}{https://github.com/ioi/isolate}} is developed under the requirements of competitive programming competition \citep{marevs2012new}.
It is used in the International Olympiad in Informatics (IOI).
The development for this project is still active under the open-source license of GNU General Public License version 2.

It needs superuser capabilities to use privileged Linux namespaces and so it is designed to be run under \code{setuid}.
This means that the binary will always run under superuser privilege, with or without \code{sudo}.
It also uses CGroup (when specified) for reliable accounting and limiting of process group's resource usage.

In general, it runs three processes: one keeper process, one proxy process, and the child process and potentially its subprocesses.
The keeper process monitors the child process and terminates it if the resource usage exceed its limit.
The proxy process becomes the parent of the child process and reports the exit status to the keeper process.
Finally, the child process runs inside its own namespace and CGroups and closely being monitored.
The resource usage is queried from the CGroup pseudo-filesystem if possible, then \code{wait4()}-reported resource usage if available, or from \code{procfs}.


\subsection{\textsc{psmon}}

From the several available resource monitoring above, there is just a small set that works under OS X specifically, and none of them support monitoring multiple processes.
Motivated by that and the fact that some researchers also used OS X on daily use, \first~developed a simple query-based resource monitoring tool.
The code is open source and licensed under the MIT license\footnote{available at \href{https://github.com/rkkautsar/psmon}{https://github.com/rkkautsar/psmon}}.

The basic mechanism is similar to those used in \textsc{runsolver} (see Section \ref{sec:resource.impl.runsolver}).
Since \code{procfs} is only available in Linux, we utilizes \textsc{psutil} to implement cross-platform process tree scanning and resource usage query.
The polling frequency is configurable, and the resource monitor is also extensible.
To handle short-living process, the notification mechanism \code{wait4()} is used.

This is just a basic implementation and by no means reliable by the requirements defined by \citet{beyerReliableBenchmarkingRequirements2019}.
But \first~hope this can be a stepping stone for the development of other tool to also targets non-Linux operating systems.
