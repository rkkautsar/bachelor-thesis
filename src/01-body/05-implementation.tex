\chapter{\chImplementation}
\label{ch:implementation}

\section{System Design}

This section discusses the design of \OurBenchmarkingTool~and its rationale.

\subsection{Architecture}
\label{sec:impl.architecture}

\begin{figure}
    \centering
    \ifdraft{
        \dummyfig{assets/diagrams/arch.tikz}
    }{
        \input{assets/diagrams/arch.tikz}
    }
    \caption{Architecture of \OurBenchmarkingTool}
    \label{fig:architecture}
\end{figure}

Figure \ref{fig:architecture} shows the architecture of \OurBenchmarkingTool, our attempt on a new benchmarking tool fulfilling most of the defined requirements.
The architecture follows the client-server design pattern, communicating through Transmission Control Protocol (TCP).
The client manages the heavy computation while the server manages the data.
Typically, the client will be in a high performance computing (HPC) cluster system while the server in a separate system, e.g. a virtual private server (VPS).

This decision to use client-server architecture is made to handle concurrent writes to the database, which is difficult to achieve in some database engines.
With a single server process to manage the database, the writes can be queued in the application level.
This provides a clean separation of computation and data.

Furthermore, the server can be separated to another system outside of the cluster system, allowing avoidance of filesystem-related issues such as locking issues on NFS (Network File System).
Long running job is arguably an anti-pattern in job scheduling, because not only it will take a long time before it's scheduled, it will also prevent other jobs from being scheduled.

\emph{Server} manages the data in the database.
It receives events through a TCP socket and optionally send replies.
To achieve extensibility, the server maintains a specified set of \emph{observers}, each listening for related events.
The events are distributed through a publisher-subscriber design pattern.
The observer will then executes its jobs, such as inserting data to the database.

\emph{Bootstrapper} is a component that will read the configuration file from the user, prepare the computing environment, and then tell the server $R \in C \times I$, the set of benchmark runs that will be executed.
Among the things prepared are the tools, benchmark instances, and database schema.
Preparing the specified tools and instances may additionally include downloading and running related setting up steps.
In short, the bootstrapping is also separated to the computation-related and data-related between the client-side and server-side.

\emph{Manager} manages the benchmark workers.
This component acts as an interface to the underlying job submitting system, or even implements its own job queue as in the case of the \emph{local} manager.
The manager is responsible for deploying, assigning tasks, and stopping the benchmark workers, making sure they finishes the assigned job.
This allows the benchmarking tool to be agnostic about the execution environment and can be extended in many ways.

\emph{Workers} do the heavy computing steps, typically in parallel.
Because the benchmark run is embarrassingly parallel\footnote{there is no effort needed to parallelize the problem since there is no dependencies between tasks}, each worker can be run as its own process without interacting with other workers.
Submitted to a HPC cluster, this allows the computation to be executed as fast as possible.
A worker is assigned a run identifier and executes the needed steps for the benchmark run after asking the context (i.e. $r = (c, i) \in R$) from the server.

A worker consists of smaller building blocks called \emph{run steps}.
The run step is executed in sequence.
In most cases, one of these steps, called the \emph{executor}, acts as a resource monitor and executes the tool configuration $c$ with the instance $i$.
The executor then measures and limits the execution of the tool.
Finally, each step can report its result to the server.

The worker only executes one specific benchmark run as opposed to requesting many jobs as its available.
This is also to prevent worker to be a long-running job.
A worker maps nicely to a job in the HPC cluster system.

\emph{Analyzer} aggregates the data from the database and analyze it, outputting a presentable result.
This component is usually used after the benchmarking is finished, but it can also be used to serve a live analysis of a benchmarking in process.
Analyzer also consists of steps that is implemented as a modular, reusable module.
This is to encourage code reuse and minimize the effort of doing the common analysis of research results.


\subsection{Messaging}

\begin{figure}
    \ifdraft{
        \dummyfig{assets/diagrams/zeromq.tikz}
    }{
        \input{assets/diagrams/zeromq.tikz}
    }
    \caption{Messaging architecture of \OurBenchmarkingTool}
    \label{fig:zmq}
\end{figure}

Figure \ref{fig:zmq} gives an overview of the messaging architecture and the overall network of \OurBenchmarkingTool.
Each process is independent to each other and can be separated across virtual nodes.
This means it can be implemented in a single node, in a cluster system, or even across clusters.
Data is transported through TCP for inter-process communication, and through local in-process (inter-thread) transportation for intra-process communication.
Communication follows some basic messaging patterns used by the \O MQ (ZeroMQ)\footnote{\href{http://zeromq.org/}{http://zeromq.org/}} messaging framework, namely \textsc{router-dealer} and \textsc{pub-sub}.

\First~decided to use \O MQ to avoid reinventing the wheel and just focus the core functionalities.
\O MQ provides many messaging patterns for many use cases.
It is also lightweight and easily available in most platform with a lot of supported languages.

The \textsc{router-dealer} patterns allows two-way communication between the party \citep{hintjens2013zeromq}.
This is used in the communication between the worker and the server gateway.
The patterns allows many workers to send events to the server and optionally request for a reply from the server.
The message sent to a \textsc{router} socket is enveloped by a unique identifier, allowing the \textsc{router} to reply to the correct \textsc{dealer}.
This powerful pattern allows reliable many to one communication between the workers and the server gateway.

On the other hand, \textsc{pub-sub} patterns follows the publisher-subscriber pattern as its name suggests \citep{hintjens2013zeromq}.
This is a fan-out pattern, on which the publisher just publish the message without caring if the message is received.
Both the publisher and subscriber does not know each other.
The \textsc{pub} socket just publish the message to the socket, and the \textsc{sub} sockets listen to one or more `topic'.
This allows fast distribution of event message received by the server gateway to the possibly many observers.
The downside is the distribution is not reliable since the message is just thrown without confirmation if the other party is ready.
This can be corrected with proper synchronization using other messaging pattern if needed.


\subsection{Benchmarking Workflow}
\begin{figure}
    \centering
    \ifdraft{
        \dummyfig{assets/pics/workflow-swimlane.png}
    }{
        \includegraphics[width=\textwidth]{assets/pics/workflow-swimlane.png}
    }
    \caption{Benchmarking workflow}
    \label{fig:swimlane}
\end{figure}

Figure \ref{fig:swimlane} presents the steps and interactions taken by each actors, namely the Client, Workers, and Server.
Aside from the already defined Workers and Server in Section \ref{sec:impl.architecture} above, Client represents the actual user interfacing with \OurBenchmarkingTool.
Note that the figure assumes the server is already started.

First, the client uses the bootstrapper to read the configuration and then send a bootstrap event to the server.
This event includes the needed information for the server to also set up the database schema.
Then the server replies its readiness to the client.
After that, the client uses the manager to spawn workers.
This is the end of the interaction needed by the user.

Then, after being scheduled by the job scheduling system used by the manager, each worker request the context for its assigned run identifier to the server.
The server replies with the context.
This includes things such as the tool and its configuration, the input instance, resource limits, etc.

Then come the main computation represented as run steps.
Each steps is executed sequentially.
After execution of the step, typically the worker will report the result to the server which in turn publish that event to observers.
Any observers listening to the event will execute its work, often time this means inserting data to the database. After there is no more run step to execute, the worker sends a finish event to the server and terminates.

As soon as soon as the bootstrapping is done, analysis can be executed from the available data in database.
This allows the flexibility of doing either on-demand analysis or live analysis.


\subsection{Benchmarking Model}

\First~decided to define the data as relational model of SQL, as opposed to nonrelational model of NoSQL.
The reason is because SQL provides an easy and fast interface for querying and aggregating data, tasks that occur often when analyzing benchmark results.
The benchmarking process itself can be defined nicely into structured relations, centering on benchmark runs.

\begin{figure}
    \centering
    \ifdraft{
        \dummyfig{assets/pics/erd.png}
    }{
        \includegraphics[width=\textwidth]{assets/pics/erd.png}
    }
    \caption{Entity-relationship diagram of \OurBenchmarkingTool's model}
    \label{fig:erd}
\end{figure}

The benchmarking process is modeled as in the entity-relationship diagram (ERD) shown in Figure \ref{fig:erd}.
The database stores every configuration defined to support reproducibility.
Among the core entities are \textsc{run}, \textsc{tool}, \textsc{parameter}, \textsc{limit}, \textsc{step}, \textsc{observer}, and \textsc{task}.
Some entities like \textsc{parameter} and \textsc{task} are grouped to another intermediate many-to-many entity, that is \textsc{parameterGroup} and \textsc{taskGroup}.
It can be seen that the relationship centers around the \textsc{run} entity.

Other modules, like the ones used as steps, can then register its own model to store its data, such as \textsc{runstatistic} (by the executor module) or \textsc{runnode} (by the system information collector module).
This supports separation of concern and encapsulation of the module.
User can use community-created module without having to consider its data model.

In fact, it is also possible to move all the data that is normally stored in the filesystem into the SQL table.
Many SQL database engine provides a BLOB data type to store binary data.
For example, \textsc{SQLite} even has an archiving tool called \code{sqlar}\footnote{\href{https://www.sqlite.org/sqlar}{https://www.sqlite.org/sqlar}} that use the database as storage just like a ZIP archive.
This allow the database to store everything needed to reproduce the benchmark.
But \first~decided not to do it to make debugging runs easier, a task which also occur surprisingly often alongside benchmarking.

\section{Implementation}

This section presents details regarding the implementation of \OurBenchmarkingTool.

\subsection{Development Environment}

\First~choose Python as the main programming language.
Specifically, Python 3 is used as its predecessor Python 2 will meet its end of the line and not be supported anymore in 2020.
It is a widely available language with huge community.
Python also has good interopability with C and C++, it's relatively easy to write wrappers of C libraries to Python.
That said, there is a huge collection of publicly available python packages in the Python Package Index (pypi)\footnote{\href{https://pypi.org/}{https://pypi.org/}}.
This allows for rapid development.

Being an interpreter and not a compiled language, Python is relatively slow.
For this project, speed can be sacrificed in place of developer experience.
Most of the CPU usage will be used by the benchmarked program anyway, so the development speed is arguably more important.

\First~use a combination of \textsc{pyenv}\footnote{\href{https://github.com/pyenv/pyenv}{https://github.com/pyenv/pyenv}} and \textsc{poetry}\footnote{\href{https://github.com/sdispater/poetry}{https://github.com/sdispater/poetry}} to manage dependencies and package publishing.
With \textsc{pyenv}, it is easy to switch between specific versions of Python and also pin a project to use specific version of Python.
This allow reproducible development environment across machines without influence from other projects using different Python version.
Additionally, testing if the software works under specific version of Python is a trivial task.
\textsc{poetry} on the other hand, manages the dependencies in a virtual environment with version locking.
This allows separate, reproducible dependencies across projects.
\textsc{poetry} also provide simple API to package and publish the project to pypi\footnote{\OurBenchmarkingTool~is published in pypi under \href{https://pypi.org/project/reprobench/}{\code{reprobench}} name}.
Under UNIX, setting up both tools is easy and works without superuser privilege, as seen in \lst~\ref{lst:impl.setup.pyenv.poetry}.

\begin{listing}
    \begin{minted}{bash}
$ curl https://pyenv.run | bash
$ pyenv install "3.7.2"
$ pyenv global "3.7.2"
$ pip install poetry
    \end{minted}
    \caption{Setting up \textsc{pyenv} and \textsc{poetry}}
    \label{lst:impl.setup.pyenv.poetry}
\end{listing}


\subsection{Configuration}



\subsection{Module}

\subsection{Server Gateway}

\subsection{Observers}

\subsection{Bootstrapper}

\subsection{Manager}

\subsection{Workers}

\subsection{Steps}


\section{Usage Scenario}
